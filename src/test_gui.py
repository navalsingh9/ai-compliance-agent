import streamlit as st
import pandas as pd
from sql_agent import ask_data_question
from document_agent import ask_documents, load_policy_vectorstore
from claude_client import ClaudeBedrockLLM
from langchain_ollama import OllamaLLM

st.set_page_config(page_title="ðŸ§ª LLM Test Runner", layout="wide")

st.title("ðŸ§ª Automated Test Runner for AI Agent")

# LLM Selection
model_choice = st.selectbox("Choose Model to Test:", ["Claude 3.5 Sonnet (Hackathon)", "Ollama (Local fallback)"])
if "Claude" in model_choice:
    llm = ClaudeBedrockLLM(api_key="syn-8008f862-4c63-4bb5-a35d-fc0ea4684cb0")
else:
    llm = OllamaLLM(model="llama3")

vs = load_policy_vectorstore()

# Test Prompt Options
test_prompts = [
    "What was the total sales in Southwest region in the last quarter?",
    "Show all orders with shipping time greater than scheduled shipping time",
    "What is our companyâ€™s policy on obsolete inventory?",
    "How many late deliveries occurred in California?",
    "Which customer segments had the highest average sales?"
]
selected = st.selectbox("Choose test prompt to run:", test_prompts)

if st.button("Run Test Prompt"):
    sql, result = ask_data_question(selected, llm)
    st.subheader("ðŸ“œ SQL Query")
    st.code(sql, language="sql")
    st.subheader("ðŸ“Š SQL Result")
    if isinstance(result, pd.DataFrame):
        st.dataframe(result)
    else:
        st.error(result)

    with st.spinner("Getting policy response..."):
        answer = ask_documents(selected, vs, llm)
        st.subheader("ðŸ“„ Policy-Based Answer")
        st.markdown(answer)